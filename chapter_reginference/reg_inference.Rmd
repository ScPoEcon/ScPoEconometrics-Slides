---
title: "ScPoEconometrics"
subtitle: "Regression Inference"
author: "Florian Oswald, Gustave Kenedi and Pierre Villedieu"
date: "SciencesPo Paris </br> `r Sys.Date()`"
output:
  xaringan::moon_reader:
    lib_dir: libs
    css: [default, "../css/scpo.css", "../css/scpo-fonts.css"]
    nature:
      beforeInit: ["../js/ru_xaringan.js"]
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      ratio: "16:9"
    includes:
      in_header: "../libs/partials/header.html"
---

layout: true

<div class="my-footer"><img src="../img/logo/ScPo-shield.png" style="height: 60px;"/></div> 

---

```{r setup, include=FALSE,warning=FALSE,message=FALSE}
options(htmltools.dir.version = FALSE)

def.chunk.hook  <- knitr::knit_hooks$get("chunk")


knitr::opts_chunk$set(
  message = FALSE,
  warning = FALSE,
  dev = "svg",
  cache = TRUE,
  fig.align = "center"
  #fig.width = 11,
  #fig.height = 5
)

knitr::knit_hooks$set(chunk = function(x, options) {
  x <- def.chunk.hook(x, options)
  ifelse(options$size != "normalsize", paste0("\n \\", options$size,"\n\n", x, "\n\n \\normalsize"), x)
})

# define vars
om = par("mar")
lowtop = c(om[1],om[2],0.1,om[4])

overwrite = FALSE

```

layout: true

<div class="my-footer"><img src="../img/logo/ScPo-shield.png" style="height: 60px;"/></div> 

---

# Recap from last week

* **Confidence Interval**

* **Hypothesis testing**

--

## Today: 

* Statistical Inference applied to regressions

---

# Back to class size and student achievments

* Take back the STAR experiment data and keep: 

  * *small* and *regular* classes
  * *Kindegarten* grade
  
* Let's consider the model:

$$ \textrm{math_score}_i = b_0 + b_1 \textrm{small}_i + e_i$$ 

* By running the regression we find:

```{r echo = FALSE}
star_df = read.csv("https://www.dropbox.com/s/bf1fog8yasw3wjj/star_data.csv?dl=1")
star_df = star_df %>%filter(star != "regular+aide" & grade == "k") 
star_df$small = 1*(star_df$star == "small")+0
star_df = star_df[complete.cases(star_df),]

reg_star = lm(math~small, star_df)
coeff_star = round(reg_star$coefficients,1)
```

$$ \hat{\textrm{math_score}_i} = `r coeff_star[1]` + `r coeff_star[2]` * \textrm{small}_i$$

* Is $b_1 = `r coeff_star[2]`$ really significantly different from 0? 

---


# Regression inference: $b$ vs $\beta$ 

* $b_0, b_1$ are the **point estimates** computed from our sample.
  * Like the sample proportion $\hat{p}$ was in our pasta example!

.pull-left[

* In fact, our model's prediction...
    $$\hat{y} = b_0 + b_1 x_1 + b_2x_2 + b_3x_3$$
]

--

.pull-right[

... is an **estimate** about an unknown, **true population line**
$$y = \beta_0 + \beta_1 x_1 + \beta_2x_2 + \beta_3x_3$$
]

where $\beta_0, \beta_1, \beta_2, \beta_3$ are the **population parameters** of interest.

--

* Let's bring what we know about Confidence Intervals, Hypothesis tests and Standard Errors to bear on those estimates!

---

# Regression Table

Here is the R `summary` of our regression:
```{r}
summary(lm(math~small, star_df))
```

---

# Understanding Regression Tables

* Let's focus on:

```{r echo=FALSE}
reg_summary_star_df = round(summary(reg_star)$coefficients,4)
reg_summary_star_df
```


* There are 3 new columns: `std_error`, `t value`, `Pr(>`&#8739;`t`&#8739;`)`.

--

Entry | Meaning
----- | ----
`Std. Error` |  Standard Error of $b_k$
`t value` |  Observed Test statistic associated to $H_0:\beta_k = 0,H_A:\beta_k \neq 0$
`Pr(>`&#8739;`t`&#8739;`)` |  p-value associated to $H_0:\beta_k = 0,H_A:\beta_k \neq 0$

--

* So, nothing really new actually.

--

* Let's focus on the `small` coefficient and make sense of each in the case of a regression. 

---

# Standard Error of $b_k$

> *Standard Error of $b_k$* $\equiv$ Standard deviation of the sampling distribution of $b_k$.

Let's imagine we could draw 1000 samples of workers from the US population. 

* We'd run 1000 regression and would get 1000 estimates for each $b_k$.

* The standard error of $b_k$ quantifies how much variation in the fitted slope $b_k$ one would expect between different samples.

---

# Standard Error of $b_\textrm{small}$

* In our case we got $\hat{\textrm{SE}}(b_\textrm{small}) = `r reg_summary_star_df[2,2]`$
  
  * Notice that we write $\hat{\textrm{SE}}$ and not ${\textrm{SE}}$ because `r reg_summary_star_df[2,2]` is the sample estimate of the real standard error of $b_\textrm{small}$

* Let's simulate the sampling distribution of $b_\textrm{small}$ as we did before.

--

.pull-left[
```{r}
library(infer)
bootstrap_distrib = star_df %>% 
  specify(formula = math~small) %>%
  generate(reps = 1000, type = "bootstrap") %>%
  calculate(stat = "slope")
```

* From our simulated distribution we get: 
```{r}
round(sd(bootstrap_distrib$stat),3)
```

]

.pull-right[
```{r, echo = FALSE, fig.height=4.25}
bootstrap_distrib %>%
  ggplot(aes(x = stat)) +
  geom_histogram(col = "white", fill = "darkgreen") +
  labs(x = "b_small",
       y = "Frequency",
       title = "Boostrap Sampling distribution") +
  theme_bw(base_size = 20)
```
]

---

# Testing $H_0$: $\beta_k = 0$?

By default, the regression output provides the results associated to following hypothesis test: 

$$\begin{align}H_0:& \beta_k = 0\\H_A:& \beta_k \neq 0\end{align}$$

* It allows to statistically test if there is a true relationship between the outcome and our regressor. 
--

* If $H_0$ is true, there is **no** relationship between outcome and our regressor. 

  * In that case observing $b_1 \neq 0$ was just chance.

--

* If $H_0$ is false, then there is a true relationship. 

---

# Test statistic and p-value

* As we saw in the previous lecture, to conduct such a test we will:

--

  * Derive the sampling distribution of our **test statistic** (`t value`) assuming $H_0$ is true, i.e. the *Null distribution*.
  
--

  * Quantify how extreme the **observed test statistic** is in this hypothetic world.

--

* Our *observed test statistic* (`t value`) equals $\frac{b}{\hat{SE}(b)}$.

  * Why not just taking $b$? We'll come back and explain this formula later.

* The **p-value** (measures the area outside of $\pm$ *observed test statistic* under the *Null distribution*.

---

# Testing $b_\textrm{small} = 0$ vs $b_\textrm{small} \neq 0$

* As we did for the *Standard Error*, we will conduct the test through a simulation exercise and compare to the result obtained in the table. 

* Let first draw the Null distribution of $\frac{b_\textrm{small}}{\hat{SE}(b_\textrm{small})}$

* If there is no relationship between the math score and class size, then *reshuffling* or *permuting* variable `small` should play no role. (remember the `gender` label!)

* Let's generate 1000 permuted samples and recompute $b_\textrm{small}$ for each.

* We can then plot the distribution of $\frac{b_\textrm{small}}{\hat{SE}(b_\textrm{small})}$ under the Null
  * Remember we got $\hat{SE}(b_\textrm{small})$ = `r round(sd(bootstrap_distrib$stat),3)` from our bootstrap distribution.


---

# Testing $b_\textrm{small} = 0$ vs $b_\textrm{small} \neq 0$

```{r}
null_distribution <- star_df %>% 
  specify(math ~ small) %>%
  hypothesize(null = "independence") %>% 
  generate(reps = 1000, type = "permute") %>% 
  calculate(stat = "slope")
null_distribution$test_stat = null_distribution$stat/sd(bootstrap_distrib$stat)
```


```{r echo=FALSE, fig.height=3.5}
null_distribution %>%
ggplot(aes(x = test_stat)) +
  geom_histogram(col = "white", fill = "darkgreen") +
  labs(x = "Test Statistic under the Null",
       y = "Frequency",
       title = "Simulated based") +
  theme_bw(base_size = 14)

```


---

# Testing $b_\textrm{small} = 0$ vs $b_\textrm{small} \neq 0$

.pull-left[

* Let's add the *observed test statistic* on the graph

```{r}
(observed_stat = reg_star$coefficients[2]/sd(bootstrap_distrib$stat))
```

]

--

.pull-right[
```{r echo=FALSE, fig.height=5}
plot_null_distrib = null_distribution %>%
ggplot(aes(x = test_stat)) +
  geom_histogram(col = "white", fill = "darkgreen") +
  geom_vline(xintercept = observed_stat, size =2) +
  labs(x = "Test Statistic under the Null",
       y = "Frequency",
       title = "Simulated based") +
  theme_bw(base_size = 20)
plot_null_distrib
```

]

--

* Quite close to the observed test statistic we get from the table: `t value` = `r reg_summary_star_df[2,3]`.

---

# Testing $b_\textrm{small} = 0$ vs $b_\textrm{small} \neq 0$

* To decide if we reject $H_0$, remember we are considering a **two-sided test** here, i.e. *more extreme* means inferior to - `r round(observed_stat,3)` **or** superior to `r round(observed_stat,3)`. 

--

* Computing the *p-value* we get 0, as in the table. 

```{r}
(p_value = mean(null_distribution$test_stat < -observed_stat | 
                  null_distribution$test_stat > observed_stat))
```

--

.pull-left[

* Graphically, it corresponds to the area outside the two black lines.

* We clearly see there is no observation that fall in this area. 

* We reject $H_0$!
]

.pull-right[
```{r echo = FALSE, fig.height=3.5}
plot_null_distrib +
    geom_vline(xintercept = -observed_stat, size =2) +
  xlim(-7,7)
  
```

]

---

# Recap

.pull-left[

Let's come back to our table

```{r echo=FALSE}
summary(lm(math~small, star_df))
```

]

--

.pull-right[

* Questions


]

---

# Regression Inference : Theory

* Up to now we presented simulation based inference. 

* We saw that bootstrap sampling distribution is a good *approximation* of the real sampling distribution of $b$

* The values reported by statistical packages like R are obtained from theory. 

* The theory is based on *large sample approximations*, i.e. one can show that the sampling distributions converge to suitable distributions, which we can then use the conduct tests.


---

# CRM assumptions

---


# Comparing simulations and theory

---


# Task 

Let's look back at the returns to education across gender. 

---


class: title-slide-final, middle

# THANKS

To the amazing [moderndive](https://moderndive.com/) team!

Big Thanks `r emo::ji("tada")` to [ungeviz](https://github.com/wilkelab/ungeviz) and `r emo::ji("confetti")` [gganimate](https://github.com/thomasp85/gganimate) for their awesome packages!

---

class: title-slide-final, middle
background-image: url(../img/logo/ScPo-econ.png)
background-size: 250px
background-position: 9% 19%

# END




|                                                                                                            |                                   |
| :--------------------------------------------------------------------------------------------------------- | :-------------------------------- |
| <a href="mailto:florian.oswald@sciencespo.fr">.ScPored[<i class="fa fa-paper-plane fa-fw"></i>]               | florian.oswald@sciencespo.fr       |
| <a href="https://github.com/ScPoEcon/ScPoEconometrics-Slides">.ScPored[<i class="fa fa-link fa-fw"></i>] | Slides |
| <a href="https://scpoecon.github.io/ScPoEconometrics">.ScPored[<i class="fa fa-link fa-fw"></i>] | Book |
| <a href="http://twitter.com/ScPoEcon">.ScPored[<i class="fa fa-twitter fa-fw"></i>]                          | @ScPoEcon                         |
| <a href="http://github.com/ScPoEcon">.ScPored[<i class="fa fa-github fa-fw"></i>]                          | @ScPoEcon                       |

