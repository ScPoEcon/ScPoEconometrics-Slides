<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
  <head>
    <title>ScPoEconometrics</title>
    <meta charset="utf-8" />
    <meta name="author" content="Florian Oswald, Gustave Kenedi and Pierre Villedieu" />
    <script src="libs/jquery/jquery.min.js"></script>
    <script src="libs/elevate-section-attrs/elevate-section-attrs.js"></script>
    <link href="libs/remark-css/default.css" rel="stylesheet" />
    <script src="https://use.fontawesome.com/5235085b15.js"></script>
    <link rel="stylesheet" href="..\css\scpo.css" type="text/css" />
    <link rel="stylesheet" href="..\css\scpo-fonts.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# ScPoEconometrics
## Regression Inference
### Florian Oswald, Gustave Kenedi and Pierre Villedieu
### SciencesPo Paris </br> 2020-04-14

---


layout: true

&lt;div class="my-footer"&gt;&lt;img src="../img/logo/ScPo-shield.png" style="height: 60px;"/&gt;&lt;/div&gt; 

---



layout: true

&lt;div class="my-footer"&gt;&lt;img src="../img/logo/ScPo-shield.png" style="height: 60px;"/&gt;&lt;/div&gt; 

---

# Recap from last week

&lt;/br&gt;

* **Confidence Interval**: A pluasible range of value for the population parameter

* **Hypothesis testing** : Null hypothesis vs Alternative hypothesis, (observed) test statistic, Null distribution, p-value

--

## Today: 

.pull-left[

* Statistical Inference in the regression framework

  * Understand and a regression table. 

* Cmparing Theory based and Simulated based inference

]

--
.pull-right[

* Classical Regression Model assumptions 

* Applications

  * Class size and student achievments 
  * Returns to education across gender 
]
  
---

# Back to class size and student achievments
 
* Let's take back the STAR experiment data, and focus on: 

  * *small* and *regular* classes
  * *Kindegarten* grade

--

* We'll consider the following model:

$$ \textrm{math_score}_i = b_0 + b_1 \textrm{small}_i + e_i$$ 

--

* Running the regression our model's prediction for student `\(i\)` math score is:



$$ \hat{\textrm{math_score}_i} = 484.4 + 8.9 * \textrm{small}_i$$

--

* So `\(b_1 = 8.9\)`. What if we would draw a new random sample of schools&lt;sup&gt;1&lt;/sup&gt; from Tennessee and redo the experiment, would we find a different value for `\(b_1\)`?


.footnote[
[1]: For simplicity we assume that schools which participated in the STAR exeriment were randomly drawn.]

--

* We know the answer is *yes*, but how much different this estimate would likely to be? 

---


# Regression inference: `\(b_k\)` vs `\(\beta_k\)` 

* `\(b_0, b_1\)` are the **point estimates** computed from our sample.
  
  * Like the sample proportion `\(\hat{p}\)` was in our pasta example!

--

.pull-left[

* In fact, our model's prediction...
    `$$\hat{y} = b_0 + b_1 x_1$$`
]

--

.pull-right[

... is an **estimate** about an unknown, **true population line**
`$$y = \beta_0 + \beta_1 x_1$$`
]

where `\(\beta_0, \beta_1\)` are the **population parameters** of interest.

--

* You will often find `\(\hat{\beta_k}\)` rather than `\(b_k\)`, both refer to sample estimate of `\(\beta_k\)`

--

* Let's bring what we know about Confidence Intervals, Hypothesis tests and Standard Errors to bear on those `\(\hat{\beta_k}\)`!

---

# Regression Table

Here is the R `summary` of our regression:

```r
summary(lm(math~small, star_df))
```

```
## 
## Call:
## lm(formula = math ~ small, data = star_df)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -164.446  -34.342   -4.342   28.554  141.554 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  484.446      1.150   421.1  &lt; 2e-16 ***
## small          8.895      1.678     5.3 1.23e-07 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 48.55 on 3357 degrees of freedom
## Multiple R-squared:  0.008298,	Adjusted R-squared:  0.008003 
## F-statistic: 28.09 on 1 and 3357 DF,  p-value: 1.233e-07
```

---

# Understanding Regression Tables

* Let's focus on:


```
##             Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept)  484.446      1.150 421.133        0
## small          8.895      1.678   5.300        0
```


* There are 3 new columns here: `std_error`, `t value`, `Pr(&gt;`&amp;#8739;`t`&amp;#8739;`)`.

--

Entry | Meaning
----- | ----
`Std. Error` |  Standard Error of `\(b_k\)`
`t value` |  Observed Test statistic associated to `\(H_0:\beta_k = 0,H_A:\beta_k \neq 0\)`
`Pr(&gt;`&amp;#8739;`t`&amp;#8739;`)` |  p-value associated to `\(H_0:\beta_k = 0,H_A:\beta_k \neq 0\)`

--

* So, nothing really new actually.

--

* Let's focus on the `small` coefficient and make sense of each entry in the case of a regression. 

---

# Standard Error of `\(b_k\)`

&gt; *Standard Error of `\(b_k\)`* `\(\equiv\)` Standard deviation of the sampling distribution of `\(b_k\)`.

Let's imagine we could redo the experiment 1000 times on 1000 different samples 

* We'd run 1000 regression and would get 1000 estimates for each `\(b_k\)`.

* The standard error of `\(b_k\)` quantifies how much variation in `\(b_k\)` one would expect across (*an infinity of*) samples.
  
---

# Standard Error of `\(b_\textrm{small}\)`

* From the table, we get `\(\hat{\textrm{SE}}(b_\textrm{small}) = 1.678\)`
  
  * Notice that we write `\(\hat{\textrm{SE}}\)` and not `\({\textrm{SE}}\)` because 1.678 is the estimate of the real standard error of `\(b_\textrm{small}\)` we get from our sample

--

* Let's simulate the sampling distribution of `\(b_\textrm{small}\)` to see where it comes from.


    
---

class:inverse

# Task 1 (10 min)

As we did for the sampling distribution of the proportion of *green pasta*, we want to generate the bootstrap distribution of `\(b_\textrm{small}\)`. 

1. Download the data from [here]("https://www.dropbox.com/s/bf1fog8yasw3wjj/star_data.csv?dl=1") and assign it to `star_df`

--

1. Filter the dataframe to keep only:
  * *small* and *regular* classes
  * *Kindegarten* grade

--

1. Create a dummy variable named `small` equal to one if `star` is equal to *small*

--

1. Keep only the rows without any NA.

--

1. Compute the bootstrap distribution of `\(b_\textrm{small}\)` based on 1000 samples drawn `star_df`. *Hint*:  Use the appropriate functions from the `infer` package. 

--

1. Plot this simulated sampling distribution and compute the standard error of `\(b_\textrm{small}\)` 

---

# Testing `\(\beta_k = 0\)` vs `\(\beta_k \neq 0\)`

By default, the regression output provides the results associated to following hypothesis test: 

`$$\begin{align}H_0:&amp; \beta_k = 0\\H_A:&amp; \beta_k \neq 0\end{align}$$`

* It allows to statistically test if there is a true relationship between the outcome and our regressor. 
--

* If `\(H_0\)` is true, there is **no** relationship between outcome and our regressor. 

  * In that case observing `\(b_1 \neq 0\)` was just chance.

--

* If `\(H_0\)` is false, then there **is** a true relationship. 

---

# Test statistic and p-value

* As we saw in the previous lecture, to conduct such a test we will:

--

  * Derive the sampling distribution of our **test statistic** (`t value`) assuming `\(H_0\)` is true, i.e. the *Null distribution*.
  
--

  * Quantify how extreme the **observed test statistic** is in this hypothetic world.

--

* Our *observed test statistic* (`t value`) equals `\(\frac{b}{\hat{SE}(b)}\)`.

  * Why not just taking `\(b\)`? We'll come back and explain this formula later.

* The **p-value** (measures the area outside of `\(\pm\)` *observed test statistic* under the *Null distribution*.

* Finally, we will see if we can reject `\(H_0\)` at the usual **significance levels**: `\(\alpha\)` = 0.1, 0.05, 0.01. (`Signif. codes` in the R summary of the regression)

---

# Testing `\(\beta_\textrm{small} = 0\)` vs `\(\beta_\textrm{small} \neq 0\)`

* We will approximate the Null distribution of `\(\frac{b_\textrm{small}}{\hat{SE}(b_\textrm{small})}\)` through a simulation exercise. 

--

* If there is no relationship between the math score and class size ($\H_0$ is true), then *reshuffling* / *permuting* the values of `small` across students should play no role.

--

.pull-left[
* Let's generate 1000 permuted samples and compute `\(b_\textrm{small}\)` for each.


```r
null_distribution &lt;- star_df %&gt;% 
  specify(math ~ small) %&gt;%
  hypothesize(null = "independence") %&gt;% 
  generate(reps = 1000, type = "permute") %&gt;% 
  calculate(stat = "slope")
```
]

--

.pull-right[

* We can compute the distribution of our test statistic `\(\frac{b_\textrm{small}}{\hat{SE}(b_\textrm{small})}\)` under the Null:


```r
null_distribution$test_stat = null_distribution$stat/sd(bootstrap_distrib$stat)
```

* Remember we got `\(\hat{SE}(b_\textrm{small})\)` = 1.689 from our bootstrap distribution.
]

  


---

# Testing `\(\beta_\textrm{small} = 0\)` vs `\(\beta_\textrm{small} \neq 0\)`


&lt;img src="reg_inference_files/figure-html/unnamed-chunk-7-1.svg" style="display: block; margin: auto;" /&gt;


---

# Testing `\(\beta_\textrm{small} = 0\)` vs `\(\beta_\textrm{small} \neq 0\)`

* The *observed test statistic* is 


```r
(observed_stat = reg_star$coefficients[2]/sd(bootstrap_distrib$stat))
```

```
##    small 
## 5.265083
```

* Quite close to the observed test statistic we get from the table: `t value` = 5.3.


--

.pull-left[
&lt;img src="reg_inference_files/figure-html/unnamed-chunk-9-1.svg" style="display: block; margin: auto;" /&gt;

]

--

.pull-right[

&lt;/br&gt; 

* Our observed test statistic is far away from the Null distribution.

* It means it is very unlikely to get `\(b_\textrm{small}\)` = 8.9 when `\(H_0\)` is true.

]

---

# Testing `\(\beta_\textrm{small} = 0\)` vs `\(\beta_\textrm{small} \neq 0\)`

* To decide if we reject `\(H_0\)`, remember we are considering a **two-sided test** here, i.e. *more extreme* means inferior to - 5.265 **or** superior to 5.265. 


--


.pull-left[

* Computing the *p-value* we get 0, as in the table. 


```r
(p_value = mean(null_distribution$test_stat &lt; -observed_stat | 
                  null_distribution$test_stat &gt; observed_stat))
```

```
## [1] 0
```

* Graphically, it corresponds to the area outside the two black lines.

  * We clearly see there is no observation that fall in this area. 
]


.pull-right[
&lt;img src="reg_inference_files/figure-html/unnamed-chunk-11-1.svg" style="display: block; margin: auto;" /&gt;

]

---

# Testing `\(\beta_\textrm{small} = 0\)` vs `\(\beta_\textrm{small} \neq 0\)`


* Since the *p-value* is equal to 0 it means that we would reject `\(H_0\)` at any significance level.

  * The p-value would always be inferior to `\(\alpha\)`.

* In other words, we can se that `\(b_\textrm{small}\)` is **statistically different from 0** at any significance level.

  * We also say that `\(b_\textrm{small}\)` is *statistically significant* (at any significance level).


---

layout: false
class: title-slide-section-red, middle

# Regression Inference: Theory

---

layout: true

&lt;div class="my-footer"&gt;&lt;img src="../img/logo/ScPo-shield.png" style="height: 60px;"/&gt;&lt;/div&gt; 

---

# Regression Inference: Theory

* Up to now we presented simulation based inference. 

* The values reported by statistical packages like R are instead obtained from theory. 

* Theoretical inference is based on **large sample approximations**.
  * One can show that the sampling distributions converge to suitable distributions.
  
* Let's have a brief overview of theory based approach. 

---

# Regression inference: Theory

* Theory-based approach uses one fundamental result: 

$$ \frac{b - \beta}{\hat{\textrm{SE}(b)}} \underset{n \rightarrow \infty}{\longrightarrow} \mathcal{N}(0,1)$$

--

* It states that the sample statistic `\(\frac{b - \beta}{\hat{\textrm{SE}(b)}}\)` converges to a *standard normal distribution* as `\(n\)` tends to infinity. 

  * `\(\hat{\textrm{SE}(b)}\)` is the sample estimate of the standard deviation of `\(b\)`
  * It is also obtained through a theoretical formula (which you can find in the [book](https://scpoecon.github.io/ScPoEconometrics/std-errors.html#se-theory)!)

--

* We don't need to simulate any sampling distribution here, we can derive it from theory and use it to construct confidence interval or to conduct tests. 

---

# Theory based Inference: Confidence Interval

* Let's take the example of a 95% Confidence Interval.

--

* Because the sampling distribution of `\(b\)` is normally shaped, we can use the ***95% rule of thumb*** about normal distributions. 

--

* We know indeed that 95% of the values of a normal distribution lie within 1.96 (~2) standard deviations of the mean.

--

* So, we can derive that a 95% CI for `\(\beta\)` is: 

`$$\textrm{CI}_{95\%} = [ b \pm 1.96*\hat{\textrm{SE}}(b)]$$`

--

* It easily generalizes to any confidence level by taking the appropriate quantile of the normal distribution. 

---

# Theory based Inference: Hypothesis testing

* As we already mentioned, the default test that is conducted by any statistical software is:

`$$\begin{align}H_0:&amp; \beta_k = 0\\H_A:&amp; \beta_k \neq 0\end{align}$$`
--

* So, **under the Null hypothesis** we get from the previous formula that:

$$ \frac{b}{\hat{\textrm{SE}(b)}} \underset{n \rightarrow \infty}{\longrightarrow} \mathcal{N}(0,1)$$ 

--

* Then we can directly compare the observed value of `\(\frac{b}{\hat{\textrm{SE}(b)}}\)` to the *standard normal distribution* which is **Null distribution** of our test statistic. 

--

* The **p-value** assoiated to our test is then equal to the area of the *standard normal distribution* outside `\(\pm\)` the observed value of `\(\frac{b}{\hat{\textrm{SE}(b)}}\)`.

---


# Classical Regression Model

* Whether the inference is made from theory of simulations, some assumptions have to be met for this inference to be valid.

* The set of assumptions needed defines the *Classical Regression Model* (CRM)

--

* Before looking at these assumptions, let's see the small but important modifications we apply to our model (back to [*lecture 4*](https://raw.githack.com/ScPoEcon/ScPoEconometrics-Slides/master/chapter3/chapter3.html#1)):

  * We already mentioned the distinction between the sample estimate `\(b_k\)` (or `\(\hat{\beta_k}\)`) and the population parameter `\(\beta_k\)`.
  
  * In the same way, we distinguish `\(e\)`, the sample error, from `\(\varepsilon\)` the error term from the true population model: 
  
  `$$y_i = \beta_0 + \beta_1 x_{1,i} + ... + \beta_k x_{k,i} + \varepsilon_i$$`
  
---


# CRM Assumptions

1. The data are **not linearly dependent**: Each variable provides new information for the outcome, and it cannot be replicated as a linear combination of other variables.

--

2. The mean of the residuals conditional on `\(x\)` should be zero, `\(E[\varepsilon|x] = 0\)`. Notice that this also means that `\(Cov(\varepsilon,x) = 0\)`, i.e. that the errors and our explanatory variable(s) should be *uncorrelated*.

--

3. The data are drawn from a **random sample** of size `\(n\)`: observation `\((x_i,y_i)\)` comes from the exact same distribution, and is independent of observation `\((x_j,y_j)\)`, for all `\(i\neq j\)`.

--

4. The variance of the error term `\(\varepsilon\)` is the same for each value of `\(x\)`: `\(Var(\varepsilon|x) = \sigma^2\)`. This property is called **homoskedasticity**.

--

5. The error is normally distributed, i.e. `\(\varepsilon \sim \mathcal{N}(0,\sigma^2)\)` 
  * This last assumption allows to avoid large sample apprximations, but it is never used in practice since samples are sufficiently large `\((n \ge 30)\)`.

---

# Comparing Simulation and Theory based inference

* Theory and simulated based approaches often yields very similar results.

--

* Coming back to `\(b_\textrm{small}\)`, here is a recap of what we found:

Estimate | Theory |  Simulation 
--------- | ------ | --------
Std. Error   | 1.678 |  1.689
Observed test stat.| 5.3 | 5.265
p-value | 0 | 0

--


* Let's have a look at Confidence Intervals from both approaches. 

---

# Comparing Confidence Intervals 

* From theory we have: `\(\textrm{CI}_{95\%} = [8.9 \pm 1.96*1.678]\)`

```r
lower_bound_theory = 8.9 - 1.96*1.678
upper_bound_theory = 8.9 + 1.96*1.678
(CI_theory = c(lower_bound_theory, upper_bound_theory))
```

```
## [1]  5.61112 12.18888
```

--

* From simulation (*percentile method*): 

```r
lower_bound_simul = quantile(bootstrap_distrib$stat,0.025)
upper_bound_simul = quantile(bootstrap_distrib$stat,0.975)
(CI_simul = c(lower_bound_simul, upper_bound_simul))
```

```
##      2.5%     97.5% 
##  5.616591 12.244725
```

--

* Again, both appraoches yields very similar results. 

--

* We used simulation based inference to give you the intuition behind statistical inference.

---

# Comparing Confidence Intervals

&lt;img src="reg_inference_files/figure-html/unnamed-chunk-14-1.svg" style="display: block; margin: auto;" /&gt;


---

class:inverse

# Task 2.1 (10 min)

Let's go back to our question of returns to education and gender. 

1. Load the data `CPS1985` from the `AER` package and look back at the `help` to get the definition of each variable: `?CPS1985`

1. Create the`log_wage` variable equal to the log of `wage`.

--

1. Regress `log_wage` on `gender` and `education`, and save it as `reg1`. 

  3.1 Interpret each coefficient.
  
  3.2 Are the coefficients statistically significant? At which significance level? 
  
--

1. Regress the `log_wage` on `gender`, `education` and their interaction `gender*education`, save it as `reg2`. 

  4.1 How do you interpret the coefficient associated to `\(female*education\)`
  
  4.2 Can we reject the nullity of this coefficient at the 5% level? At 10%?  
  
---

class:inverse

# Task 2.2 (10 min)

`\(5.\)` Produce a scatterplot of the relationship between the log wage and the level of education.

--

`\(6.\)` Add the *regression line* with `geom_smooth`. What does this line represents?

--

`\(7.\)` Let's illustrate what the shaded area stands for.

  `\(\quad 7.1\)` Draw one bootstrap sample from our `cps` data. 

  `\(\quad 7.2\)` Regress the `log_wage` on `gender`, `education` and their interaction `gender*education`, save it as `reg_bootstrap`.

  `\(\quad 7.3\)` From `reg_bootstrap` extract and save the value of the intercept for men as `intercept_men_bootstrap` and the value of the slope for men as `slope_men_bootstrap`. Do the same for women.

  `\(\quad 7.4\)` Add both predicted lines from this bootstrap sample to the previous plot (*Hint*: use `geom_abline` (x2))
  
---


# Illustrating Uncertainty

.pull-left[
![](../img/gifs/wages.gif)

]

.pull-right[
&lt;/br&gt;
* [`ungeviz`](https://github.com/wilkelab/ungeviz) and `gganimate` bring you: Moving Lines!

* We took 20 bootstrap samples from our data

* You can see how different data points are included in each bootstrap sample.

* Those different points imply different regression lines.

* You should remember those moving lines when looking at the shaded area!

]

---

# Teaser for the Next (last!) session


---



class: title-slide-final, middle

# THANKS

To the amazing [moderndive](https://moderndive.com/) team!

Big Thanks 🎉 to [ungeviz](https://github.com/wilkelab/ungeviz) and 🎊 [gganimate](https://github.com/thomasp85/gganimate) for their awesome packages!

---

class: title-slide-final, middle
background-image: url(../img/logo/ScPo-econ.png)
background-size: 250px
background-position: 9% 19%

# END




|                                                                                                            |                                   |
| :--------------------------------------------------------------------------------------------------------- | :-------------------------------- |
| &lt;a href="mailto:florian.oswald@sciencespo.fr"&gt;.ScPored[&lt;i class="fa fa-paper-plane fa-fw"&gt;&lt;/i&gt;]               | florian.oswald@sciencespo.fr       |
| &lt;a href="https://github.com/ScPoEcon/ScPoEconometrics-Slides"&gt;.ScPored[&lt;i class="fa fa-link fa-fw"&gt;&lt;/i&gt;] | Slides |
| &lt;a href="https://scpoecon.github.io/ScPoEconometrics"&gt;.ScPored[&lt;i class="fa fa-link fa-fw"&gt;&lt;/i&gt;] | Book |
| &lt;a href="http://twitter.com/ScPoEcon"&gt;.ScPored[&lt;i class="fa fa-twitter fa-fw"&gt;&lt;/i&gt;]                          | @ScPoEcon                         |
| &lt;a href="http://github.com/ScPoEcon"&gt;.ScPored[&lt;i class="fa fa-github fa-fw"&gt;&lt;/i&gt;]                          | @ScPoEcon                       |

    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script src="../js/ru_xaringan.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false,
"ratio": "16:9"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
