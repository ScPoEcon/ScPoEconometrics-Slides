<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>ScPoEconometrics</title>
    <meta charset="utf-8" />
    <meta name="author" content="Florian Oswald, Gustave Kenedi and Pierre Villedieu" />
    <link href="libs/remark-css/default.css" rel="stylesheet" />
    <link href="libs/countdown/countdown.css" rel="stylesheet" />
    <script src="libs/countdown/countdown.js"></script>
    <script src="https://use.fontawesome.com/5235085b15.js"></script>
    <link rel="stylesheet" href="../css/scpo.css" type="text/css" />
    <link rel="stylesheet" href="../css/scpo-fonts.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# ScPoEconometrics
## Intro To Causality
### Florian Oswald, Gustave Kenedi and Pierre Villedieu
### SciencesPo Paris </br> 2021-02-24

---


layout: true

&lt;div class="my-footer"&gt;&lt;img src="../img/logo/ScPo-shield.png" style="height: 60px;"/&gt;&lt;/div&gt; 

---



layout: true

&lt;div class="my-footer"&gt;&lt;img src="../img/logo/ScPo-shield.png" style="height: 60px;"/&gt;&lt;/div&gt; 

---

# Quick "Quiz" on Last Week's Material

1\. From your ***computer*** üëâ connect to [***www.wooclap.com/SCPOSLR***](https://app.wooclap.com/SCPOSLR)

&amp;nbsp; &amp;nbsp; &amp;nbsp; ***OR***

2\. From your ***phone*** üëâ flash QR code below

&lt;img src="chapter_causality_files/figure-html/qr_code_quiz.png" width="300px" style="display: block; margin: auto;" /&gt;

---

# Today - Introduction to Causal Inference

* ***Causality*** versus ***correlation***

* The ***Potential Outcome Framework*** a.k.a. Rubin's Causal Model

* ***Randomized controlled trials*** (RCTs)

* Follow up on the empirical application of *class size* and *student performance*

---

# Why do we care about causality?

Many of the *interesting questions* we might want to answer with data are causal

--

- ***Understanding*** the world

  - *Social sciences*: Why do people behave in the way they do?
  - *Health sciences*: Why do people get sick? Which medicine can cure them?

--

- Causal understanding is also of first interest to **policymakers**

  - How to lower unemployment?
  - How to improve student learning?
  - Whether governments should care about the level of public debt?

--

- Note that some questions we might want to answer are not causal 
  - Most *Artificial Intelligence* tasks only care about **prediction**
  - *Example*: predicting whether a photo is of a dog or a cat is vital to how Google Images works, but it doesn't care what *caused* the photo to be of a dog or a cat.

---

# Causality and Economics

- Making causal inference from data can be seen as economists' *comparative advantage* among the social sciences!

- Plenty of fields do statistics. But very few make it standard training for their students to understand causality.

- Economists' endeavour to establish causal relationships is also what makes them useful both in the private (e.g. tech companies) and public sector (e.g. policy advisors). 

--

- Ok, that's enough preaching üòÖ


---

# The Concept of Causality

__Causality__: what are we talking about? 

- We say that `X` *causes* `Y`

--

  - if we were to intervene and *change* the value of `X` ***without changing anything else***...
    
--

  - then `Y` would also change ***as a result***.
  
--

- The key point here is the ***without changing anything else***, often referred as the **ceteris paribus (*all else equal*) assumption**.   
(*latin* makes things seem more complicated ü§ì)

--

- ‚ö†Ô∏è It does **NOT** mean that `X` is the only factor that causes `Y`.

---

# Correlation vs Causation

***Correlation does not equal causation*** has become a ubiquitous mantra, but can you tell why it is true?

--

Some correlations obviously don't imply causation ([e.g. spurious correlation website](https://www.tylervigen.com/spurious-correlations)).

--

&lt;img src="../img/photos/spurious.png" width="800px" style="display: block; margin: auto;" /&gt;

---

# Correlation vs Causation: Smoking and Lung Cancer

But not all correlations are so easy to rule out

--

***Does smoking cause lung cancer?***

--

.pull-left[
- Today, we know the answer is *YES*! 

- But let's go back in the 1950's

  - We are at the start of a big increase in deaths from lung cancer...
  
  - ... which is happening after a fast growth in cigarette consumption
]

--

.pull-right[
&lt;img src="../img/photos/Smoking_lung_cancer.png" width="400px" style="display: block; margin: auto;" /&gt;
]

--

- It's very tempting to claim that smoking causes lung cancer based on this graph.

---

# Correlation vs Causation: Smoking and Lung Cancer

At the time many people were still skeptical, including some famous statisticians:

--

.pull-left[
***Macro confouding factors***:  

Other macro factors which can cause cancers also changed between 1900 and 1950:

  - Tarring of roads,
  
  - Inhalation of motor exhausts (leaded gasoline fumes),
  
  - General greater air pollution.
]

--

.pull-right[
***Self selection***: 

Smokers and non-smokers may be different in the first place: 
  
  - __Selection on observable characteristics__: age, education, income, etc.
  
  - __Selection on unobservable characteristics__: genes (the hypothetical confounding genome theory of [Fisher](https://en.wikipedia.org/wiki/Ronald_Aylmer_Fisher)). 
]

---

# How Can We Tell?

- Sometimes correlations are just pure *artefacts*: there is no causal relationship between the variables of interest.

- In some other cases, there are both correlation and causality but not of the same **magnitude**, or even the same **direction**.

--

- So how can we make causal inference then? 

- The ***Potential Outcomes Framework*** will be our guide.



---
layout: false
class: title-slide-section-red, middle

# Causal Inference

---
layout: true

&lt;div class="my-footer"&gt;&lt;img src="../img/logo/ScPo-shield.png" style="height: 60px;"/&gt;&lt;/div&gt; 

---

# The Potential Outcomes Framework

Often called the **Rubin Causal Model** in memory of the statistician **Donald Rubin** who generalised and formalized this model in the 1970's.

--

***Key idea***: Each individual can be exposed to **multiple alternative treatment states**.
  - smoking cigarrettes, smoking cigars or not smoking,
  - growing up in a poor vs a middle class neighborhood vs a rich neighborhood,
  - being in a small or a big class.
  
--

.pull-left[
For practicality, let this treatment variable `\(D_i\)` be a binary variable:

$$
D_i = \begin{cases} 
                    1 \textrm{ if individual `\(i\)` is treated} \\\\ 
                    0 \textrm{ if individual `\(i\)` is not treated} 
      \end{cases}
$$
]

--

.pull-right[

***Treatment group***  
all the individuals such that `\(D_i = 1\)`.

***Control group***  
all the individuals such that `\(D_i = 0\)`.
]

---


# The Potential Outcomes Framework

* In this framework, each individual has two ***potential outcomes***, but only one ***observed outcome*** `\(Y_i\)`:
  
  - `\(Y_i^1\)`: *potential outcome if individual `\(i\)` receives the treatment* `\((D_i = 1)\)`,
  
  - `\(Y_i^0\)`: *potential outcome if individual `\(i\)` does not receive the treatment* `\((D_i = 0)\)`.

--

* From these we can define the ***individual treatment effect*** `\(\delta_i\)`:

$$ \delta_i = Y_i^1 - Y_i^0$$

* `\(\delta_i\)` measures the **causal effect of the treatment `\((D_i)\)`** on outcome `\(Y\)` for individual `\(i\)`.

---

# The Potential Outcomes Framework

* In real life we only observe `\(Y_i\)` which can be written as:

`$$Y_i = D_i * Y_i^1 + (1- D_i)*Y_i^0$$`

--

* ***Fundamental Problem of Causal Inference***: for any individual `\(i\)`, we only observe one of either potential outcomes, and thus we cannot compute `\(\delta_i\)` [(Holland, 1986)](http://people.umass.edu/~stanek/pdffiles/causal-holland.pdf).

--

* The potential outcome that is not observed exists in principle, it is called the ***counterfactual outcome***.

--

Group | `\(Y_i^1\)` | `\(Y_i^0\)`
--------|:---------:|:---------:
Treatment group `\((D_i = 1)\)` &amp;nbsp; &amp;nbsp; | &amp;nbsp; &amp;nbsp; Observable as `\(Y_i\)` &amp;nbsp; &amp;nbsp; | Counterfactual
Control group `\((D_i = 0)\)` | Counterfactual | &amp;nbsp; &amp;nbsp; Observable as `\(Y_i\)` &amp;nbsp; &amp;nbsp;

--

* Since the treatment effect *cannot* be observed at the individual level, we estimate population averages.

---

# Average Treatment Effect (ATE)

Broadest possible average effect: **A**verage **T**reatment **E**ffect (***ATE***)

`\begin{align}
ATE &amp;= \mathop{\mathbb{E}}(\delta_i) \\
    &amp;= \mathop{\mathbb{E}}(Y_i^1 - Y_i^0) \\ 
    &amp;= \mathop{\mathbb{E}}(Y_i^1) - \mathop{\mathbb{E}}(Y_i^0)
\end{align}`
  
* The ATE simply measures the ***average of individual treatment effects over the whole population***. 
  
  * The `\(\mathop{\mathbb{E}}(.)\)` operator stands for **expectation** or *population mean*.
  
  * The `\(\mathop{\mathbb{E}}(.)\)` operator is linear, in other words, `\(\mathop{\mathbb{E}}(X+Y) = \mathop{\mathbb{E}}(X) + \mathop{\mathbb{E}}(Y)\)` with `\(X\)` and `\(Y\)` being two random variables.

---

# Average Treatment on the Treated (ATT)

Other ***conditional*** average treatment effects may be of interest:

* The **A**verage **T**reatment Effect on the **T**reated (***ATT***)

`\begin{align}
 ATT &amp;= \mathop{\mathbb{E}}(\delta_i | D_i = 1) \\
     &amp;= \mathop{\mathbb{E}}(Y_i^1 - Y_i^0 | D_i = 1) \\
     &amp;= \mathop{\mathbb{E}}(Y_i^1 | D_i = 1) - \mathop{\mathbb{E}}(Y_i^0 | D_i = 1)
\end{align}`

* The ATT measures the ***average treatment effect conditional on being in the treatment group***.

    * The `\(\mathop{\mathbb{E}}(.|D = x)\)` operator stands for **conditional expectation**. It refers to the expectation over a subcategory of the entire population, namely people who satisfy the condition `\(D = x\)`.
  * The `\(\mathop{\mathbb{E}}(.|D = x)\)` operator is also linear.

---

# Average Treatment on the Untreated (ATU)

Other ***conditional*** average treatment effects may be of interest:

* The **A**verage **T**reatment Effect on the **U**ntreated (***ATU***)

`\begin{align}
 ATU &amp;= \mathop{\mathbb{E}}(\delta_i | D_i = 0) \\
     &amp;= \mathop{\mathbb{E}}(Y_i^1 - Y_i^0 | D_i = 0) \\
     &amp;= \mathop{\mathbb{E}}(Y_i^1 | D_i = 0) - \mathop{\mathbb{E}}(Y_i^0 | D_i = 0)
\end{align}`

* The ATU measures the ***average treatment effect conditional on being in the control group***.

--

* In the majority of cases, ATE `\(\neq\)` ATT `\(\neq\)` ATU!

---

# Example

*Example:* Potential outcomes for 10 students of being in a class of 7 students `\((Y^1)\)` or 15 students `\((Y^0)\)` on GPA (0-10)

.pull-left[
Student | &amp;nbsp; &amp;nbsp; `\(Y^1\)` &amp;nbsp; &amp;nbsp; | &amp;nbsp; &amp;nbsp; `\(Y^0\)` &amp;nbsp; &amp;nbsp; | &amp;nbsp; &amp;nbsp; `\(\delta\)` &amp;nbsp; &amp;nbsp; 
-----------|:---------:|:---------:|:---------:|
1 | 5 | 2 | 3
2 | 6 | 4 | 2
3 | 3 | 6 | -3
4 | 5 | 4 | 1
5 | 10 | 8 | 2
6 | 2 | 4 | -2
7 | 5 | 2 | 3
8 | 6 | 4 | 2
9 | 2 | 9 | -7
10 | 8 | 2 | 6
]

--

.pull-right[

$$
`\begin{align}
\color{red}{\text{ATE}} &amp;= \mathbb{E}(Y^1) - \mathbb{E}(Y^0) \\
&amp;= 5.2 - 4.5 \\
&amp;= 0.7
\end{align}`
$$

`\(\rightarrow\)` the ***average*** causal effect of being in small relative to large class on GPA is 0.7 points.

‚ö†Ô∏è not all students benefited equally from the treatment!

]

---

# Example

Now, imagine a benevolent and omniscient school director assigns students to the treatment that maximizes their GPA

--

.pull-left[
Student | &amp;nbsp; &amp;nbsp; `\(Y\)` &amp;nbsp; &amp;nbsp; | &amp;nbsp; &amp;nbsp; `\(D\)` &amp;nbsp; &amp;nbsp; | &amp;nbsp; &amp;nbsp; `\(\delta\)`&amp;nbsp; &amp;nbsp;
-----------|:---------:|:---------:|:---------:
1 | 5 | 1 | 3
2 | 6 | 1 | 2
3 | 6 | 0 | -3
4 | 5 | 1 | 1
5 | 10 | 1 | 2
6 | 4 | 0 | -2
7 | 5 | 1 | 3
8 | 6 | 1 | 2
9 | 9 | 0 | -7
10 | 8 | 1 | 6
]

--

.pull-right[

$$
`\begin{align}
\color{red}{\text{ATT}} &amp;= \mathbb{E}(\delta | D = 1) \\
&amp;\approx 2.71
\end{align}`
$$

$$
`\begin{align}
\color{red}{\text{ATU}} &amp;= \mathbb{E}(\delta | D = 0) \\
&amp;= -4
\end{align}`
$$

$$
`\begin{align}
\color{red}{\text{ATE}} &amp;= 7/10 \times \text{ATT} + 3/10 \times \text{ATU} \\
&amp;= 7/10 \times 2.71 + 3/10 \times (-4) \\
&amp;= 0.7
\end{align}`
$$

]


---

# The Problem of Causal Inference

* In practice, we have the same **missing data problem** for computing the ATE, ATT or ATU as we did for `\(\delta_i\)`. Either `\(Y_i^1\)` or `\(Y_i^0\)` is missing for each `\(i\)`.

--

* From the data, we can compute the **S**imple **D**ifference in mean **O**utcomes (***SDO***) for both groups:

$$
`\begin{align}
SDO &amp;= \mathop{\mathbb{E}}(Y_i^1|D_i=1) - \mathop{\mathbb{E}}(Y_i^0|D_i=0) \\
&amp;= \frac{1}{N_T}\sum_{i=1}^{N_T}(Y_i|D_i=1) - \frac{1}{N_C}\sum_{i=1}^{N_C}(Y_i|D_i=0)
\end{align}`
$$ 

--

* From our example, we obtain:  `\(SDO \approx 6.43 - 6.33 \approx 0.1\)` (much smaller than the 0.7 ATE)

--

* Almost always, such a difference **will fail to capture the causal treatment effect**.

--

* Notice that this kind "naive" comparison is often done by journalists, politicians, badly trained scientists (but not you now! üòâ).

---

# Problems with Naive Comparisons

Let's rewrite the SDO to make the individual treatment effect `\((\delta_i)\)` appear in the equation. 

`\begin{align}
  SDO &amp;= \mathop{\mathbb{E}}(Y_i^1|D_i=1) - \mathop{\mathbb{E}}(Y_i^0|D_i=0) \\ &amp;= \mathop{\mathbb{E}}(Y_i^0 + \delta_i | D_i = 1) - \mathop{\mathbb{E}}(Y_i^0 | D_i = 0)
\end{align}`

--

For now, suppose **treatment effect is constant** across people: for all `\(i, \delta_i = \delta\)`.

--

Then,

$$
  SDO = \delta + \mathop{\mathbb{E}}(Y_i^0 | D_i = 1) - \mathop{\mathbb{E}}(Y_i^0 | D_i = 0)
$$

And because `\(ATE = \mathop{\mathbb{E}}(\delta_i) = \mathop{\mathbb{E}}(\delta) = \delta\)` (by assumption), we get: 


`\begin{equation}
  SDO = ATE + \underbrace{\mathop{\mathbb{E}}(Y_i^0 | D_i = 1) - \mathop{\mathbb{E}}(Y_i^0 | D_i = 0)}_\text{Selection bias}
\end{equation}`

---

# Problems with Naive Comparisons

Let's now relax the assumption that the treatment effect is constant among all individuals.

After [some tedious calculations](https://mixtape.scunning.com/potential-outcomes.html#simple-difference-in-means-decomposition) that we skip, the SDO can now be decomposed as: 

`\begin{align}
  SDO &amp;= ATE + \underbrace{\mathop{\mathbb{E}}(Y_i^0 | D_i = 1) - \mathop{\mathbb{E}}(Y_i^0 | D_i = 0)}_\text{Selection bias} \\
  &amp; \quad \quad  \quad \quad + \underbrace{(1-\pi)(ATT - ATU)}_\text{Heterogenous treatment effect bias}
\end{align}`

where `\(1 - \pi\)` denotes the share of people in the control group.

--

So there is a novel source of bias that comes from the potential ***heterogeneity in the individual treatment effect*** `\(\delta_i\)`.

--

* ***Selection bias***: those who attend university are likely to have higher baseline cognitive skills (regardless of whether they actually attend college).
* ***Heterogeneous treatment effect bias***: those who attend university may improve their cognitive skills more at university because they are more motivated.

---

class:inverse

# Task 1: SDO, ATE and Randomization

<div class="countdown" id="timer_60369b32" style="top:0;right:0;" data-warnwhen="0">
<code class="countdown-time"><span class="countdown-digits minutes">10</span><span class="countdown-digits colon">:</span><span class="countdown-digits seconds">00</span></code>
</div>

Let's compute these various quantities and biases with some toy data (i.e. data we generated ourselves).



1. Load the data [here](https://www.dropbox.com/s/oqc3vq1m9eyp1d6/toy_data_2.csv?dl=1). The `group` variable corresponds to whether the individual has been treated or not, the `Y0` variable corresponds to the potential outcome if the individual does not receive the treatment `\((Y_i^0)\)` while `Y1` corresponds to the potential outcome if the individual receives the treatment `\((Y_i^1)\)`. Create a new variable containing the observed outcome `\((Y_i)\)` and the individual treatment effect `\((\delta_i)\)`. (Recall that `\(Y_i = D_i * Y_i^1 + (1 - D_i) Y_i^0\)` and `\(\delta_i = Y_i^1 - Y_i^0\)`.)

1. Compute the ***ATE*** and the ***SDO***. Is there is any *bias*? Is it large in magnitude?

1. In this new [dataset](https://www.dropbox.com/s/0qfsonzz1t9gkxi/toy_data_random.csv?dl=1) we've randomly assigned the same individuals to the treatment and control groups. Compute the ***SDO under randomization***. Remember that you need to recompute `\(Y_i\)` because the assignment is not the same anymore. If you got it right, the bias should be very close to 0. Why is it not exactly 0? 

1. *To do at home*:  Compute the value of the ***selection bias*** and the ***heterogenous treatment effect bias*** and check that we have `$$SDO = ATE + \textrm{selection bias} + \textrm{heterogenous treatment effect bias}$$`


---

# Randomization solves the problem of causal inference!

* ***Randomized experiments***: you ***randomly*** assign people to a treatment and a control group.

* In this case, the treatment assignement is **independent** of the potential outcomes.

--

* In particular, there is no reason for `\(\mathop{\mathbb{E}}(Y_i^0 | D_i = 1)\)` to be different from `\(\mathop{\mathbb{E}}(Y_i^0 | D_i = 0)\)`

  * Therefore the ***selection bias is equal to 0***.
  
--
  
* In the same way, there is no reason for `\(\mathop{\mathbb{E}}[\delta_i]\)` to be different in the treatment and control group. 

  * There `\(ATT = ATU\)`, implying the ***heterogenous treatment effect bias will also be 0***.

---

# Randomization solves the problem of causal inference!

With random assignment we have: 

$$ SDO = \mathop{\mathbb{E}}(Y_i^1|D_i=1) - \mathop{\mathbb{E}}(Y_i^0|D_i=0) = ATE$$ 

üëâ We can directly estimate the ATE from the data!

---

layout: false
class: title-slide-section-red, middle

# Randomized Experiments

---
layout: true

&lt;div class="my-footer"&gt;&lt;img src="../img/logo/ScPo-shield.png" style="height: 60px;"/&gt;&lt;/div&gt; 

---

# Randomized Experiments

- Often called **R**andomized **C**ontrolled **T**rials (RCT).

- The first RCTs were conducted a long time ago (18th and 19th century), mainly in **Medecine**. 

- In the beginning of the 20th century they were popularized by famous statisticians like **J. Neyman** or **R.A. Fisher**. 

- Since then they have had a growing influence and have progressively become a reliable [tool for public policy evaluation](https://www.povertyactionlab.org/fr). 

- As for economics, the **2019 Nobel Price in Economics** was awarded to three exponents of RCTs, [Abhijit Banerjee, Esther Duflo and Michael Kremer](https://www.economist.com/finance-and-economics/2019/10/17/a-nobel-economics-prize-goes-to-pioneers-in-understanding-poverty), "for their experimental approach to alleviating global poverty".

---

# Back to class size and students' achievement

Last week we regressed average student math or reading scores on class size.

`$$\textrm{math score}_i = b_0 + b_1 \textrm{class size}_i + e_i$$`
We briefly discussed why `\(b_1^{OLS}\)` could only establish an ***association*** and not a ***causal relationship***.

--

* **Student sorting**: There is selection into schools with different sized classes. Suppose parents have a prior that smaller classes are better, they will try to get their kids into those schools.

--

* **Teacher sorting**: Teachers may sort in schools with smaller classes because it‚Äôs easier to teach a small rather than a large class, and if there is competition for those places then higher quality teachers will have an advantage.

--

* **Location effect**: Large classes may be more common in wealthier and bigger cities, while small classes may be more likely in poorer rural areas.

--

An RCT would take care of all these biases!

---

# The Project STAR Experiment

Tennessee **S**tudent/**T**eacher **A**chievement **R**atio Experiment (see [Krueger (1999)](http://piketty.pse.ens.fr/files/Krueger1999.pdf))

* Funded by Tennesse legislature for a total cost of approx. $12 million.

* The experiment started in the 1985-1986 school year and lasted four years.

--

* 11,600 students and their teachers where **randomly assigned** to one of the following 3 groups from kindergarten through third grade:

  1. ***Small class***: 13-17 students per teacher,
  
  2. ***Regular class***: 22-25 students,
  
  3. ***Regular/aide class***: 22-25 students with a full-time teacher's *aide*.

--

* Randomization occurred within schools.

* Students' math and reading skills were tested around March each year.

--

* There was a problem of ***non-random attrition*** but we will ignore it.

---

class:inverse

# Task 2: STAR data

<div class="countdown" id="timer_60369c31" style="top:0;right:0;" data-warnwhen="0">
<code class="countdown-time"><span class="countdown-digits minutes">10</span><span class="countdown-digits colon">:</span><span class="countdown-digits seconds">00</span></code>
</div>

1. Load the *STAR* data from [here](https://www.dropbox.com/s/bf1fog8yasw3wjj/star_data.csv?dl=1) and assign it to an object called `star_df`.

1. Read the help for `AER::STAR` to understand what the variables correspond to. (Note: the data has been *reshaped* so don't mind the "k", "1", etc. in the variable names in the help.)

1. What's the unit of observation? Which variable contains: (i) the (random) class assignment, (ii) the student's class grade, (iii) the outcomes of interest?

1. How many observations are there? Why so many?

1. Why are there so many `NA`s? What do they correspond to?

1. Keep only cases with no `NA`s with the following code:  
`star_df &lt;- star_df[complete.cases(star_df),]`

1. Let's check how well the randomization was done by doing ***balancing checks***.  
Compute the average percentage of girls, african americans, and free lunch qualifiers by grade *and* treatment class. (*Hint*: The following computes the percentage of girls (without the relevant `dplyr` verbs):
`share_female = mean(gender == "female") * 100`.)



---

# The Project STAR Experiment

We just saw that in an RCT the Average Treatment Effect is obtained by computing the differences in outcomes between the treatment and control groups.

Let's only focus on:

- One treatment group: **small classes**,

- One control group: **regular classes**,

- One grade: **kindergarten** (k).

--



grade | test | mean regular | mean small | ATE
--------|---------|:---------:|:---------:|:---------:
k | math | 484.45 | 493.34 | 8.9
k | read | 435.76 | 441.13 | 5.37

What's the interpretation for these ATEs? 

--

That's nice but can't we put this in regression form?

---

# RCT in Regression Form

$$ Y_i = D_i Y_i^1 + (1 - D_i) Y_i^0 $$

--

Factoring by `\(D_i\)` and replacing `\(Y_i^1 - Y_i^0\)` by `\(\delta_i\)`, we get:

`$$\begin{align} Y_i &amp;=Y_i^0 +D_i (Y_i^1 - Y_i^0) \\ &amp;= Y_i^0 +D_i \delta_i \end{align}$$`

--

Assuming `\(\delta_i = \delta\)`, for all `\(i\)`,

`$$Y_i = Y_i^0 + D_i \delta$$`

--

Adding `\(\mathbb{E}[Y_i^0] - \mathbb{E}[Y_i^0] = 0\)` to the right-hand side:

`$$\begin{align} Y_i &amp;= \mathbb{E}[Y_i^0] + D_i \delta + Y_i^0 - \mathbb{E}[Y_i^0] \\ &amp;= b_0 + \delta D_i + e_i \end{align}$$`
where `\(b_0 = \mathbb{E}[Y_i^0]\)` and `\(e_i = Y_i^0 - \mathbb{E}[Y_i^0]\)`

---

# The Project STAR Experiment: Regression

The last equation looks exactly like the simple regression model we saw last week! (with `\(\delta = b_1\)`)

Let's therefore estimate the ATE of being assigned to a small class size on math scores.

--

We want to estimate the following model: `\(\text{math score}_i = b_0 + \delta \text{small}_i + e_i\)`, with

$$
\text{small}_i = \begin{cases} 
                    1 \textrm{  if assigned to a small class}  \\\\ 
                    0 \textrm{  if assigned to a regular class} 
      \end{cases}
$$

.pull-left[

```r
star_df_k_small &lt;- star_df %&gt;%
  filter(
    star %in% c("regular", "small") &amp;
      grade == "k") %&gt;% 
  mutate(small = (star == "small"))
```


```r
star_df_k_small %&gt;% count(star, grade)

star_df_k_small %&gt;% count(small)
```

]

.pull-left[

```
## # A tibble: 2 x 3
##   star    grade     n
##   &lt;chr&gt;   &lt;chr&gt; &lt;int&gt;
## 1 regular k      1781
## 2 small   k      1578
```

```
## # A tibble: 2 x 2
##   small     n
##   &lt;lgl&gt; &lt;int&gt;
## 1 FALSE  1781
## 2 TRUE   1578
```
]

---

# The Project STAR Experiment: Regression

Regression model we want to estimate: `\(\text{math score}_i = b_0 + \delta \text{small}_i + e_i\)`


```r
lm(math ~ small, star_df_k_small)
```

```
## 
## Call:
## lm(formula = math ~ small, data = star_df_k_small)
## 
## Coefficients:
## (Intercept)    smallTRUE  
##     484.446        8.895
```

--

Recall that: `\(b_0 = \mathbb{E}[Y_i^0]\)` and `\(\delta = \mathbb{E}[Y_i | D_i = 1] - \mathbb{E}[Y_i | D_i = 0]\)`

.pull-left[

```r
b_0 = mean(star_df_k_small$math[
    star_df_k_small$small == FALSE])
b_0
```

```
## [1] 484.4464
```
]

.pull-right[

```r
delta = mean(star_df_k_small$math[
    star_df_k_small$small == TRUE]) - 
  mean(star_df_k_small$math[
    star_df_k_small$small == FALSE])
delta
```

```
## [1] 8.895193
```
]

---

# Regression with a Dummy Variable: Graphically

Contrary to last week, the regressor in our regression is a ***dummy variable***, i.e. a variable that takes the values TRUE or FALSE (1 or 0).

&lt;img src="chapter_causality_files/figure-html/unnamed-chunk-13-1.svg" style="display: block; margin: auto;" /&gt;

---

# Regression with a Dummy Variable: Graphically

Contrary to last week, the regressor in our regression is a ***dummy variable***, i.e. a variable that takes the values TRUE or FALSE (1 or 0).

&lt;img src="chapter_causality_files/figure-html/unnamed-chunk-14-1.svg" style="display: block; margin: auto;" /&gt;

---

# Regression with a Dummy Variable: Graphically

Contrary to last week, the regressor in our regression is a ***dummy variable***, i.e. a variable that takes the values TRUE or FALSE (1 or 0).

&lt;img src="chapter_causality_files/figure-html/unnamed-chunk-15-1.svg" style="display: block; margin: auto;" /&gt;


---

# Regression with a Dummy Variable: Graphically

Contrary to last week, the regressor in our regression is a ***dummy variable***, i.e. a variable that takes the values TRUE or FALSE (1 or 0).

&lt;img src="chapter_causality_files/figure-html/unnamed-chunk-16-1.svg" style="display: block; margin: auto;" /&gt;

---

# Regression with a Dummy Variable: Formally

Recall the regression model: `\(\text{math score}_i = b_0 + \delta \text{small}_i + e_i\)`

`\(\begin{align} \mathbb{E}[\textrm{math score} | \text{small}_i = 0]&amp;= \mathbb{E}[b_0 + \delta \text{small}_i + e_i | \text{small}_i = 0] \\ &amp;= b_0 + \delta \mathbb{E}[\text{small}_i| \text{small}_i = 0] + \mathbb{E}[e_i|\text{small}_i = 0] \\ &amp;= b_0 \end{align}\)`

--

`\(\begin{align} \mathbb{E}[\textrm{math score} | \text{small}_i = 1]&amp;= \mathbb{E}[b_0 + \delta \text{small}_i + e_i | \text{small}_i = 1] \\ &amp;= b_0 + \delta \mathbb{E}[\text{small}_i| \text{small}_i = 1] + \mathbb{E}[e_i|\text{small}_i = 1] \\ &amp;= b_0 + \delta \end{align}\)`

--

`\(\begin{align} ATE &amp;= \mathbb{E}[\textrm{math score} | \text{small}_i = 1] - \mathbb{E}[\textrm{math score} | \text{small}_i = 0] \\ &amp;= b_0 + \delta - b_0 \\ &amp;= \delta \end{align}\)`

--

We knew this already but we now understand why this is true ‚úåÔ∏è

---

class:inverse

# Task 3: Your Turn!

<div class="countdown" id="timer_60369d89" style="top:0;right:0;" data-warnwhen="0">
<code class="countdown-time"><span class="countdown-digits minutes">10</span><span class="countdown-digits colon">:</span><span class="countdown-digits seconds">00</span></code>
</div>

1. Filter the dataset to only keep first graders and the small class and regular class groups.

1. Compute the average math score for both groups, and the difference between the two. (Use base `R`.)

1. Create a dummy variable `treatment` equal to `TRUE` if student is in treatment group (i.e. small class size) and `FALSE` if in control group (i.e. regular class size). See slide 33 for how to create a dummy variable.

1. Regress math score on the treatment dummy variable. Are the results in line with question 2?

1. How do you interpret these coefficients?

---

# Shortcomings of RCTs 

RCTs have very strong ***internal validity***, that is they can convincingly establish causal links.

However, they have some shortcomings:

* RCT are often **infeasible**:

  * RCTs are **costly**,
  * RCTs may face some **ethical issues**: some *treatments* simply cannot be given to people,
  * RCTs take time and we may be **time constrained**.

--

* **Interpretation** of the results:

  * ***External validity***: To what extent can the results from a given RCT be generalized to other contexts (countries, populations,...)?
  
  * Uncovering the mechanisms that are at stake may be difficult,
  
  * Imperfect randomization, attrition, ...

---


# What comes next? 

* So if we cannot rely on RCTs to make our life easy, it means we have to find a way to make causal inference from ***observational data*** (as opposed to ***experimental data***).

--

* It brings us back to models 

  - In causal inference, the *model* is our idea of what the process that *generated the data* is.

  - We have to make some assumptions about what this is!

--

2 broad cases:

* ***selection occurs on observable characteristics***: *multiple regression* (next week!)

* ***selection occurs on unobservable characteristics***: *regression discontinuity design* (lecture 10) or  *difference-in-differences* (not covered but set of slides online!)

---

&lt;br&gt;
&lt;br&gt;

.center[
&lt;img src="../img/photos/correlation_funny.png" width="1000px" style="display: block; margin: auto;" /&gt;
]

---

class: title-slide-final, middle
background-image: url(../img/logo/ScPo-econ.png)
background-size: 250px
background-position: 9% 19%

# SEE YOU NEXT WEEK!




|                                                                                                            |                                   |
| :--------------------------------------------------------------------------------------------------------- | :-------------------------------- |
| &lt;a href="mailto:florian.oswald@sciencespo.fr"&gt;.ScPored[&lt;i class="fa fa-paper-plane fa-fw"&gt;&lt;/i&gt;]               | florian.oswald@sciencespo.fr       |
| &lt;a href="https://github.com/ScPoEcon/ScPoEconometrics-Slides"&gt;.ScPored[&lt;i class="fa fa-link fa-fw"&gt;&lt;/i&gt;] | Slides |
| &lt;a href="https://scpoecon.github.io/ScPoEconometrics"&gt;.ScPored[&lt;i class="fa fa-link fa-fw"&gt;&lt;/i&gt;] | Book |
| &lt;a href="http://twitter.com/ScPoEcon"&gt;.ScPored[&lt;i class="fa fa-twitter fa-fw"&gt;&lt;/i&gt;]                          | @ScPoEcon                         |
| &lt;a href="http://github.com/ScPoEcon"&gt;.ScPored[&lt;i class="fa fa-github fa-fw"&gt;&lt;/i&gt;]                          | @ScPoEcon                       |
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://cdnjs.cloudflare.com/ajax/libs/remark/0.14.0/remark.min.js"></script>
<script src="../js/ru_xaringan.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false,
"ratio": "16:9"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
